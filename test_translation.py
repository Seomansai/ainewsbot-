#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ OpenRouter
"""

import os
from openai import OpenAI

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

def test_translation():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é OpenRouter"""
    
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    
    if not openrouter_key:
        print("‚ùå OPENROUTER_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        return
    
    client = OpenAI(
        api_key=openrouter_key,
        base_url="https://openrouter.ai/api/v1"
    )
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã (—Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã AI –Ω–æ–≤–æ—Å—Ç–µ–π)
    test_texts = [
        "OpenAI releases GPT-4 Turbo with improved reasoning capabilities",
        "Meta's new AI model achieves state-of-the-art performance on benchmark tests while reducing computational costs by 40%",
        "Researchers develop neural network architecture that can process multimodal data with unprecedented accuracy"
    ]
    
    print("ü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OpenRouter –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞...\n")
    
    # –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    models = [
        "openai/gpt-3.5-turbo",
        "anthropic/claude-3-haiku",
        "meta-llama/llama-3.1-8b-instruct"
    ]
    
    for model in models:
        print(f"üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å: {model}")
        print("=" * 60)
        
        for i, text in enumerate(test_texts[:1], 1):  # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
            print(f"üìù –¢–µ—Å—Ç {i}:")
            print(f"–û—Ä–∏–≥–∏–Ω–∞–ª: {text}")
            
            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {
                            "role": "system", 
                            "content": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤. –ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã, –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã –∏ —Å–º—ã—Å–ª. –î–µ–ª–∞–π –ø–µ—Ä–µ–≤–æ–¥ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∏ —á–∏—Ç–∞–±–µ–ª—å–Ω—ã–º –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏. –°–æ—Ö—Ä–∞–Ω—è–π —Å—Ç–∏–ª—å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞."
                        },
                        {
                            "role": "user", 
                            "content": f"–ü–µ—Ä–µ–≤–µ–¥–∏ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π:\n\n{text}"
                        }
                    ],
                    temperature=0.2,
                    max_tokens=1500
                )
                
                translation = response.choices[0].message.content.strip()
                print(f"–ü–µ—Ä–µ–≤–æ–¥: {translation}")
                print("-" * 60)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ: {e}")
                print("-" * 60)
        
        print()

if __name__ == "__main__":
    test_translation() 