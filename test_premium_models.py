#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç –ø—Ä–µ–º–∏—É–º –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞
"""

import os
from openai import OpenAI

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

def test_premium_models():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–º–∏—É–º –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    
    if not openrouter_key:
        print("‚ùå OPENROUTER_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        return
    
    client = OpenAI(
        api_key=openrouter_key,
        base_url="https://openrouter.ai/api/v1"
    )
    
    # –°–ª–æ–∂–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –Ω–æ–≤–æ—Å—Ç—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_title = "Meta's new AI model achieves state-of-the-art performance"
    test_description = """Meta announced its latest large language model, Llama 3.1, which demonstrates unprecedented capabilities in reasoning, mathematics, and multilingual understanding. The model, trained on over 15 trillion tokens, achieves state-of-the-art performance on multiple benchmarks including MMLU, GSM8K, and HumanEval coding tasks. Meta claims the model outperforms GPT-4 on several key metrics while being more efficient in computational resources. The company is releasing the model under an open-source license, making it freely available for commercial use. This release marks a significant milestone in democratizing advanced AI capabilities."""
    
    print("üèÜ –¢–µ—Å—Ç –ø—Ä–µ–º–∏—É–º –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π...\n")
    print(f"üìù –¢–µ—Å—Ç–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å:")
    print(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {test_title}")
    print(f"–û–ø–∏—Å–∞–Ω–∏–µ: {test_description[:200]}...")
    print("=" * 80)
    
    # –ü—Ä–µ–º–∏—É–º –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    premium_models = [
        ("anthropic/claude-3.5-sonnet", "Claude 3.5 Sonnet (–¢–û–ü)", "~$3/1M —Ç–æ–∫–µ–Ω–æ–≤"),
        ("openai/gpt-4o", "GPT-4o (OpenAI)", "~$5/1M —Ç–æ–∫–µ–Ω–æ–≤"),
        ("anthropic/claude-3-haiku", "Claude 3 Haiku (–±—ã—Å—Ç—Ä–∞—è)", "~$0.25/1M —Ç–æ–∫–µ–Ω–æ–≤"),
        ("openai/gpt-3.5-turbo", "GPT-3.5 Turbo (—ç–∫–æ–Ω–æ–º–Ω–∞—è)", "~$1.5/1M —Ç–æ–∫–µ–Ω–æ–≤")
    ]
    
    # –ü—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞
    summary_prompt = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∂—É—Ä–Ω–∞–ª–∏—Å—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –Ω–æ–≤–æ—Å—Ç—è—Ö –æ–± –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ.

–ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–ü–†–ê–í–ò–õ–ê:
1. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–º, –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º
2. –í—ã–¥–µ–ª–∏ –≥–ª–∞–≤–Ω—É—é —Å—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
3. –î–æ–±–∞–≤—å –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ (—Ü–∏—Ñ—Ä—ã, –∫–æ–º–ø–∞–Ω–∏–∏, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)
4. –°–æ—Ö—Ä–∞–Ω—è–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã: AI, ML, API, GPU, LLM
5. –û–±—ä–µ–º: 2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º
6. –°—Ç–∏–ª—å: –∫–∞–∫ –∫—Ä–∞—Ç–∫–∞—è –Ω–æ–≤–æ—Å—Ç–Ω–∞—è —Å–≤–æ–¥–∫–∞

–°–æ–∑–¥–∞–≤–∞–π –ø–µ—Ä–µ—Å–∫–∞–∑ –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏."""
    
    for model, name, cost in premium_models:
        print(f"\nüéØ {name} ({cost})")
        print("-" * 60)
        
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": summary_prompt},
                    {"role": "user", "content": f"–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ —ç—Ç–æ–π –Ω–æ–≤–æ—Å—Ç–∏:\n\n–ó–∞–≥–æ–ª–æ–≤–æ–∫: {test_title}\n–¢–µ–∫—Å—Ç: {test_description}"}
                ],
                temperature=0.2,
                max_tokens=1000
            )
            
            summary = response.choices[0].message.content.strip()
            print(f"‚úÖ –ü–µ—Ä–µ—Å–∫–∞–∑:\n{summary}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        
        print()

if __name__ == "__main__":
    test_premium_models() 